model:
  family: gpt2
  n_dims: 5
  n_embd: 64
  n_head: 2
  n_layer: 3
  n_positions: 101
  dropout: 0
out_dir: ./models
test_run: false
training:
  batch_size: 64
  curriculum:
    dims:
        end: 5
        inc: 1
        interval: 10000
        start: 1
    points:
        end: 10
        inc: 1
        interval: 10000
        start: 5
  data: gaussian
  keep_every_steps: 100000
  keep_every_steps_until_phase_transition: 1000000000000000 
  learning_rate: 0.0001
  num_tasks: null
  resume_id: null
  save_every_steps: 500
  task: linear_regression
  task_kwargs: {}
  train_steps: 500000
  num_training_examples: null
  weight_decay: 0
wandb:
  entity: marcomolinari4
  log_every_steps: 500
  name: null
  notes: ''
  project: train toy regressor